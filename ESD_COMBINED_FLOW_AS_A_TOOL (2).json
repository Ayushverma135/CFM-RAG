{
  "id": "4ababfd8-f2c1-4982-b758-b5f20683064e",
  "data": {
    "nodes": [
      {
        "data": {
          "id": "ConditionalRouter-yYK9X",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "LLM that will classify the user query and map it to the respective use case",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nimport os\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Text-Based Router\"\n    description = \"Routes an input message to a corresponding output based on exact text match.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"password_reset\", \"reactivate_account\", \"chit_chat\"],\n            info=\"The default route to take if no matching text is found.\",\n            value=\"chitchat\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n            info=\"LLM that will classify the user query and map it to the respective use case\",\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        #Output(display_name=\"Variable ID\", name=\"identify_use_case\", method=\"get_or_create_session_var_response\"),\n        Output(display_name=\"Password Reset\", name=\"password_reset\", method=\"password_reset_response\"),\n        Output(display_name=\"Reactivate Account\", name=\"reactivate_account\", method=\"reactivate_account_response\"),\n        Output(display_name=\"Chitchat\", name=\"chit_chat\", method=\"chitchat_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n    \n    def _get_input_text(self):\n        self.log(f'into _get_input_text function')\n        var_to_check = f\"use_case_{self.session_id}\"\n        self.log(f'variable to check : {var_to_check}')\n        get_var = os.environ.get(var_to_check, \"\")\n        return get_var\n    \n    MISSING_INPUTS_MSG = \"Missing required inputs: llm\"\n    def identify_use_case(self) -> str:\n        if not self.llm:\n            raise ValueError(self.MISSING_INPUTS_MSG)\n        try:\n            system_prompt = {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are an intent classifier agent. Your task is given an input user query you need to find it's intent and \\n\"\n                \"assign it to one of the classes which seems most relevant to you mentioned below:\\n\"\n                \"1) password_reset\\n\"\n                \"2) reactivate_account\\n\"\n                \"3) chit_chat\\n\"\n                \"Note : Respond with only the class name mentioned above.\"\n                \"Example:\\n\"\n                    \"I forgot my password -> password_reset.\\n\"\n                    \"I can’t access my account -> reactivate_account.\\n\"\n                    \"I am unable to login -> password_reset. \\n\"\n                ),\n            }\n            # system_prompt = {\n            # \"role\": \"system\",\n            # \"content\": \"\"\"\n            #     You are an intent classifier agent. Your task is given an input user query you need to find it's intent and \\n\"\n            #     assign it to one of the classes which seems most relevant to you mentioned below:\n            #     1) password_reset\\n\n            #     2) reactivate_account\\n\n            #     3) chit_chat\\n\n                \n            #     Example:\\n\"\n            #     I forgot my password -> password_reset.\\n\n            #     I can’t access my account -> reactivate_account.\\n\n            #     I am unable to login -> password_reset.\\n\n            #     Hello, are you there? ->  chit_chat.\\n\n                \n            #     Special Considertion:\n            #     If the input is any confirmation phrase (yes, yes please, go ahead, please proceed, I confirm, sure, okay), you MUST return the same tag from the previous turn.\\n\n            #     If input is server names like P1, P2, P3 and P4, you MUST return the same tag you returned on the *previous* turn.\\n\n            #     \"DOORS\" -> you MUST return the same tag you returned on the *previous* turn.\\n\n            #     \"I have the valid access\" -> you MUST return the same tag you returned on the *previous* turn.\\n\n            #     \"my user ID is ABC123\" -> you MUST return the same tag you returned on the *previous* turn.\\n\n                \n            #     Example chat flows 1:\\n\n            #     Turn 1 -> User: I want to reset the password (Tag: password_reset)\n            #               Agent: Do you want to go further with password Reset\n            #     Turn 2 -> User: yes (Tag: password_reset)\n            #               Agent: Could you please provide the name of the application for which you want to reset the password?\n            #     Turn 3 -> User: DOORS application (Tag: password_reset)\n            #               Agent: Do you have the valid access to the DOORS application?\n            #     Turn 4 -> User: yes (Tag: password_reset)\n            #               Agent: Provide me the valid names of servers for resetting your password\n            #     Turn 5 -> User: P1, P2, P3 and P4 (Tag: password_reset)\n            #               Agent: Provide me your user ID\n            #     Turn 6 -> User: AWBCD1234 (any alpha-numeric value) (Tag: password_reset)\n            #               Agent: Do you want to confirm with all provided information?\n            #     Turn 7 -> User: yes (Tag: password_reset)\n            #               Agent: Your ticket has been successfully created successfully!\n            #     **End of Conversation**\n\n            #     Example chat flows 2:\\n\n            #     Turn 1 -> User: I want to reactivate my account (Tag: reactivate_account)\n            #               Agent: Do you want to go further with account reactivation?\n            #     Turn 2 -> User: yes (Tag: reactivate_account)\n            #               Agent: Could you please provide the name of the application for which you want to reactivate the account?\n            #     Turn 3 -> User: DOORS application (Tag: reactivate_account)\n            #               Agent: Do you have the valid access to the DOORS application?\n            #     Turn 4 -> User: yes (Tag: reactivate_account)\n            #               Agent: Provide me the valid names of servers for reactivating your account\n            #     Turn 5 -> User: P1, P2, P3 and P4 (Tag: reactivate_account)\n            #               Agent: Provide me your user ID\n            #     Turn 6 -> User: AWBCD1234 (any alpha-numeric value) (Tag: reactivate_account)\n            #               Agent: Do you want to confirm with all provided information?\n            #     Turn 7 -> User: yes (Tag: reactivate_account)\n            #               Agent: Your ticket has been successfully created successfully!\n            #     **End of Conversation**\n            #     \"\"\"\n            # }\n\n\n            user_message = {\n            \"role\": \"user\",\n            \"content\": f\"\"\"Input Query: \"{self.message}\"\\n\n            Based on the user query\n            select the most appropriate intent (return only one class name):\"\"\",}\n            \n            # Get judge's decision\n            response = self.llm.invoke([system_prompt, user_message])\n            self.log(f'response : {response}')\n            try:\n                data = response.content.strip()\n                self.log(f'use case identified : {data}')\n                return data\n            except ValueError as ve:\n                self.status = f\"Error: {ve!s}\"\n                self.log(str(ve))\n                return \"\"                \n        except (RuntimeError, ValueError) as e:\n            self.status = f\"Error: {e!s}\"\n            self.log(str(e))\n            # Fallback to first model\n            return \"\"\n    \n    def get_or_create_session_var_response(self) -> str:\n        self.log('into get_or_create_session_var_response function')\n        intent_data = self._get_input_text()\n        self.log(f'intent identified : {intent_data}')\n        # when variable doesn't exists\n        if len(intent_data) <= 1:\n            self.log('intent variable not set')\n            use_case_identified = self.identify_use_case()\n            if len(use_case_identified) == 0 :\n                raise ValueError(\"Unable to identify the use case\")\n\n            os.environ[f\"use_case_{self.session_id}\"] = use_case_identified\n            updated_intent = self._get_input_text()\n            self.log(f'variable created with intent :  {updated_intent}')\n            data = updated_intent\n            self.status = data\n            return data\n        else:\n            data = intent_data\n            self.status = data\n            return data\n    \n    # def get_or_create_session_var_response(self) -> str:\n    #     \"\"\"\n    #     Retrieve the stored intent for this session, but if the user's current\n    #     message indicates a different intent, clear and reclassify.\n    #     \"\"\"\n    #     var_name = f\"use_case_{self.session_id}\"\n    #     stored_intent = os.environ.get(var_name, \"\").strip()\n        \n    #     # Classify the current message\n    #     fresh_intent = \"\"\n    #     try:\n    #         fresh_intent = self.identify_use_case().strip()\n    #     except Exception:\n    #         # If classification fails, fall back to stored intent\n    #         fresh_intent = stored_intent\n    \n    #     # If a new intent is detected, reset the stored intent\n    #     if stored_intent and fresh_intent and fresh_intent != stored_intent:\n    #         self.log(f\"New intent '{fresh_intent}' detected, resetting old intent '{stored_intent}'\")\n    #         os.environ.pop(var_name, None)\n    #         stored_intent = \"\"\n    \n    #     # If no stored intent, store the fresh one\n    #     if not stored_intent:\n    #         if not fresh_intent:\n    #             raise ValueError(\"Unable to identify the use case\")\n    #         os.environ[var_name] = fresh_intent\n    #         stored_intent = fresh_intent\n    #         self.log(f\"Session variable set to: {stored_intent}\")\n    \n    #     self.status = stored_intent\n    #     return stored_intent\n\n\n        \n    def evaluate_condition(self, input_text: str) -> str:\n        \"\"\"\n        Evaluates the input text to determine which output to trigger.\n        \"\"\"\n        input_text = input_text.strip().lower()  # Normalize input text for comparison\n        \n        if input_text == \"password_reset\":\n            return \"password_reset\"\n        elif input_text == \"reactivate_account\":\n            return \"reactivate_account\"\n        else :\n            return \"chit_chat\"\n    \n    def stop_nodes(self,nodes_to_stop):\n        if not self.__iteration_updated:\n            self.__iteration_updated = True\n            for node in nodes_to_stop:\n                self.stop(node)\n\n    def password_reset_response(self) -> Message:\n        var_id = self.get_or_create_session_var_response()\n        input_text = self._get_input_text()\n        self.log(f\"into password reset, intent : {input_text}\")\n        if self.evaluate_condition(input_text) == \"password_reset\":\n            self.status = input_text\n            self.stop_nodes([\"reactivate_account\",\"chit_chat\"])\n            return self.message\n        #self.stop_nodes(['password_reset'])\n        return Message(content=\"\")\n\n    def reactivate_account_response(self) -> Message:\n        var_id = self.get_or_create_session_var_response()\n        input_text = self._get_input_text()\n        self.log(f\"into account reacivate, intent : {input_text}\")\n        if self.evaluate_condition(input_text) == \"reactivate_account\":\n            self.status = input_text\n            self.stop_nodes([\"password_reset\",\"chit_chat\"])\n            return self.message\n        #self.stop_nodes(['reactivate_account'])\n        return Message(content=\"\")\n\n    def chitchat_response(self) -> Message:\n        var_id = self.get_or_create_session_var_response()\n        input_text = self._get_input_text()\n        self.log(f\"into chit chat, intent : {input_text}\")\n        if self.evaluate_condition(input_text) == \"chit_chat\":\n            self.status = input_text\n            self.stop_nodes([\"password_reset\",\"reactivate_account\"])\n            return self.message\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        return build_config",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_route": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "password_reset",
                  "reactivate_account",
                  "chit_chat"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_route",
                "value": "chitchat",
                "display_name": "Default Route",
                "advanced": true,
                "dynamic": false,
                "info": "The default route to take if no matching text is found.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on exact text match.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text-Based Router",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "password_reset",
                "hidden": null,
                "display_name": "Password Reset",
                "method": "password_reset_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "reactivate_account",
                "hidden": null,
                "display_name": "Reactivate Account",
                "method": "reactivate_account_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "chit_chat",
                "hidden": null,
                "display_name": "Chitchat",
                "method": "chitchat_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "default_route",
              "message",
              "llm",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-yYK9X",
        "measured": {
          "height": 388,
          "width": 320
        },
        "position": {
          "x": -67.87329151411598,
          "y": 885.3744862358873
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-yCbbe",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a text output in the Playground.",
            "display_name": "Update to default",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "session_id"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\nimport os\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Update to default\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n    \n    def text_response(self) -> Message:\n        try:\n            var_to_delete = f\"use_case_{self.session_id}\"\n            status = os.environ.pop(var_to_delete, None)\n            self.log(status)\n            self.status = \"Variable deleted\"\n            return Message(text=\"Variable deleted\")\n\n        except Exception as e:\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return Message(text=error_message)\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-yCbbe",
        "measured": {
          "height": 227,
          "width": 320
        },
        "position": {
          "x": 1589.7757740742852,
          "y": 2843.900521430209
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Vgcoe",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Vgcoe",
        "measured": {
          "height": 190,
          "width": 320
        },
        "position": {
          "x": 1116.3257763806619,
          "y": 2634.852827268405
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-6QNmg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Please respond in the same language in which the user asks their question. \nIf user ask in English reply in English , If user ask the question in German then reply in German.\nKeep the response concise and polite.\nYou are capable of performing password reset and account reactivation as of now. So If anybody asks you about your functionalities kindly reply with the same."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-6QNmg",
        "measured": {
          "height": 254,
          "width": 320
        },
        "position": {
          "x": -116.48137840355476,
          "y": 2657.1652871258293
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-HRSWn",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\nimport httpx\nimport os\n# from langchain.chat_models import ChatOpenAI\n# from langchain.schema import HumanMessage\n# from langchain_openai import ChatOpenAI\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n    def get_token(self) -> str:\n            client_id = \"idp-99629305-eb32-4450-af6d-0762ac02ca2b-llmaas-app\"\n            client_secret = \"cidps_YUy05kngKz8GhSMFp4ghXHsHbiZt2h9BQsb6K4pP8zlTdF1Q9D8rTeHgbCFKmQJ5USqO541ogcf7cdHxDFTh5EQr2DCcz9\"\n        # X-LLM-API-CLIENT-ID -> \"IGTF-GmMfMoxTW0VIBhYhU69\"\n            url = \"https://idp.cloud.vwgroup.com/auth/realms/kums-mfa/protocol/openid-connect/token\"\n        \n            response = httpx.post(\n                url,\n                data={\n                    \"client_id\": client_id,\n                    \"client_secret\": client_secret,\n                    \"grant_type\": \"client_credentials\",\n                },\n            )\n            assert response.status_code == 200, f\"Error from Cloud IDP: {response.status_code} - {response.text}\"\n        \n            return response.json()[\"access_token\"]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        \n        \n        api_key = self.get_token()\n        headers = {\"X-LLM-API-CLIENT-ID\": \"IGTF-GmMfMoxTW0VIBhYhU69\"}\n\n        # api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=\"https://llm.ai.vwgroup.com/v1\",\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            default_headers=headers,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_parser": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Output Parser",
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "input_types": [
                  "OutputParser"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "output_parser",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_schema": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "FloatInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-HRSWn",
        "measured": {
          "height": 645,
          "width": 320
        },
        "position": {
          "x": 665.1830118027567,
          "y": 2319.7591742916866
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-RtDMM",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\nimport httpx\nimport os\n# from langchain.chat_models import ChatOpenAI\n# from langchain.schema import HumanMessage\n# from langchain_openai import ChatOpenAI\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n    def get_token(self) -> str:\n            client_id = \"idp-99629305-eb32-4450-af6d-0762ac02ca2b-llmaas-app\"\n            client_secret = \"cidps_YUy05kngKz8GhSMFp4ghXHsHbiZt2h9BQsb6K4pP8zlTdF1Q9D8rTeHgbCFKmQJ5USqO541ogcf7cdHxDFTh5EQr2DCcz9\"\n        # X-LLM-API-CLIENT-ID -> \"IGTF-GmMfMoxTW0VIBhYhU69\"\n            url = \"https://idp.cloud.vwgroup.com/auth/realms/kums-mfa/protocol/openid-connect/token\"\n        \n            response = httpx.post(\n                url,\n                data={\n                    \"client_id\": client_id,\n                    \"client_secret\": client_secret,\n                    \"grant_type\": \"client_credentials\",\n                },\n            )\n            assert response.status_code == 200, f\"Error from Cloud IDP: {response.status_code} - {response.text}\"\n        \n            return response.json()[\"access_token\"]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        \n        \n        api_key = self.get_token()\n        headers = {\"X-LLM-API-CLIENT-ID\": \"IGTF-GmMfMoxTW0VIBhYhU69\"}\n\n        # api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=\"https://llm.ai.vwgroup.com/v1\",\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            default_headers=headers,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_parser": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Output Parser",
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "input_types": [
                  "OutputParser"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "output_parser",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_schema": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "FloatInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-RtDMM",
        "measured": {
          "height": 645,
          "width": 320
        },
        "position": {
          "x": -640.9450032699402,
          "y": 1120.1680655256814
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-i4iQL",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\r\nimport re\r\nfrom collections.abc import Generator\r\nfrom typing import Any\r\n\r\nfrom langflow.base.io.chat import ChatComponent\r\nfrom langflow.inputs import BoolInput, HandleInput\r\nfrom langflow.io import DropdownInput, MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\nfrom langflow.schema.dataframe import DataFrame\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema.properties import Source\r\nfrom langflow.utils.constants import (\r\n    MESSAGE_SENDER_AI,\r\n    MESSAGE_SENDER_NAME_AI,\r\n    MESSAGE_SENDER_USER,\r\n)\r\n\r\nclass ChatOutput(ChatComponent):\r\n    display_name = \"Chat Output\"\r\n    description = \"Display a chat message in the Playground.\"\r\n    icon = \"MessagesSquare\"\r\n    name = \"ChatOutput\"\r\n    minimized = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Text\",\r\n            info=\"Message to be passed as output.\",\r\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\r\n            required=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"should_store_message\",\r\n            display_name=\"Store Messages\",\r\n            info=\"Store the message in the history.\",\r\n            value=True,\r\n            advanced=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"sender\",\r\n            display_name=\"Sender Type\",\r\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\r\n            value=MESSAGE_SENDER_AI,\r\n            advanced=True,\r\n            info=\"Type of sender.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"sender_name\",\r\n            display_name=\"Sender Name\",\r\n            info=\"Name of the sender.\",\r\n            value=MESSAGE_SENDER_NAME_AI,\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session_id\",\r\n            display_name=\"Session ID\",\r\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"data_template\",\r\n            display_name=\"Data Template\",\r\n            value=\"{text}\",\r\n            advanced=True,\r\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"background_color\",\r\n            display_name=\"Background Color\",\r\n            info=\"The background color of the icon.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"chat_icon\",\r\n            display_name=\"Icon\",\r\n            info=\"The icon of the message.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text_color\",\r\n            display_name=\"Text Color\",\r\n            info=\"The text color of the name\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"clean_data\",\r\n            display_name=\"Basic Clean Data\",\r\n            value=True,\r\n            info=\"Whether to clean the data\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Message\",\r\n            name=\"message\",\r\n            method=\"message_response\",\r\n        ),\r\n    ]\r\n\r\n    def _build_source(\r\n        self,\r\n        source: str | None,\r\n        icon: str | None,\r\n        display_name: str | None,\r\n        source_id: str | None,\r\n    ) -> Source:\r\n        \"\"\"\r\n        Accepts exactly the four values returned by\r\n        get_properties_from_source_component():\r\n            (source, icon, display_name, source_id)\r\n        \"\"\"\r\n        source_dict: dict[str, Any] = {}\r\n        if source_id:\r\n            source_dict[\"id\"] = source_id\r\n        if display_name:\r\n            source_dict[\"display_name\"] = display_name\r\n        if source:\r\n            source_dict[\"source\"] = source\r\n        return Source(**source_dict)\r\n\r\n    async def message_response(self) -> Message:\r\n        # 1) Convert input to text\r\n        text = self.convert_to_string()\r\n\r\n        # 2) Prepare Message object\r\n        if isinstance(self.input_value, Message):\r\n            message = self.input_value\r\n            message.text = text\r\n        else:\r\n            message = Message(text=text)\r\n\r\n        # 3) Set metadata\r\n        message.sender = self.sender\r\n        message.sender_name = self.sender_name\r\n        message.session_id = self.session_id\r\n        message.flow_id = getattr(self.graph, \"flow_id\", None)\r\n\r\n        # Unpack and build source metadata\r\n        src, icon, disp, src_id = self.get_properties_from_source_component()\r\n        message.properties.source = self._build_source(src, icon, disp, src_id)\r\n        message.properties.icon = self.chat_icon or icon\r\n        message.properties.background_color = self.background_color\r\n        message.properties.text_color = self.text_color\r\n\r\n        # 4) Detect end-of-conversation and clear the session_id\r\n        # final_pattern = (\r\n        #     r\"^(?:password reset request has been successfully processed.*\"\r\n        #     r\"|password reset request has been successfully created.*)\"\r\n        # )\r\n        final_pattern = (\r\n            r\"Error during API call:*\"\r\n        )\r\n        if re.match(final_pattern, text.strip()):\r\n            message.session_id = \"\"\r\n            self.log(\"Detected end-of-conversation; cleared message.session_id\")\r\n\r\n        # 5) Store message if enabled (only when session_id is non-empty)\r\n        if message.session_id and self.should_store_message:\r\n            stored_message = await self.send_message(message)\r\n            self.message.value = stored_message\r\n            message = stored_message\r\n\r\n        self.status = message\r\n        return message\r\n\r\n    def _validate_input(self) -> None:\r\n        if self.input_value is None:\r\n            raise ValueError(\"Input data cannot be None\")\r\n        if isinstance(self.input_value, list) and not all(\r\n            isinstance(item, (Message, Data, DataFrame, str))\r\n            for item in self.input_value\r\n        ):\r\n            invalid = [\r\n                type(item).__name__\r\n                for item in self.input_value\r\n                if not isinstance(item, (Message, Data, DataFrame, str))\r\n            ]\r\n            raise TypeError(f\"Expected Data or DataFrame or Message or str, got {invalid}\")\r\n\r\n    def _safe_convert(self, data: Any) -> str:\r\n        try:\r\n            if isinstance(data, str):\r\n                return data\r\n            if isinstance(data, Message):\r\n                return data.get_text()\r\n            if isinstance(data, Data):\r\n                text = data.get_text()\r\n                if text is None:\r\n                    raise ValueError(\"Empty Data object\")\r\n                return text\r\n            if isinstance(data, DataFrame):\r\n                df = data.copy()\r\n                if self.clean_data:\r\n                    df = (\r\n                        df.dropna(how=\"all\")\r\n                        .replace(r\"^\\s*$\", \"\", regex=True)\r\n                        .replace(r\"\\n+\", \"\\n\", regex=True)\r\n                    )\r\n                return (\r\n                    df.replace(r\"\\|\", r\"\\\\|\", regex=True)\r\n                    .applymap(\r\n                        lambda x: str(x).replace(\"\\n\", \"<br/>\")\r\n                        if isinstance(x, str)\r\n                        else x\r\n                    )\r\n                    .to_markdown(index=False)\r\n                )\r\n            return str(data)\r\n        except Exception as e:\r\n            raise ValueError(f\"Error converting data: {e}\") from e\r\n\r\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\r\n        self._validate_input()\r\n        if isinstance(self.input_value, list):\r\n            return \"\\n\".join(self._safe_convert(item) for item in self.input_value)\r\n        if isinstance(self.input_value, Generator):\r\n            return self.input_value\r\n        return self._safe_convert(self.input_value)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-i4iQL",
        "measured": {
          "height": 190,
          "width": 320
        },
        "position": {
          "x": 1657.189781632654,
          "y": 474.54909999898416
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-uA1pU",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-uA1pU",
        "measured": {
          "height": 190,
          "width": 320
        },
        "position": {
          "x": 1877.6221909170722,
          "y": 1619.5784726212444
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-HHgHz",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass CustomComponent(Component):\n    display_name = \"Session ID\"\n    description = \"Current Session ID if the flow\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Message:\n        data = Message(text=self.session_id)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "description": "Current Session ID if the flow",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "Session ID",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "hidden": null,
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "CustomComponent"
        },
        "dragging": false,
        "id": "CustomComponent-HHgHz",
        "measured": {
          "height": 146,
          "width": 320
        },
        "position": {
          "x": 554.014350150831,
          "y": 1386.6480694748366
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "id": "LangflowRunner-cCNgz",
        "type": "genericNode",
        "position": {
          "x": 986.4711247381159,
          "y": 639.5264699559342
        },
        "data": {
          "id": "LangflowRunner-cCNgz",
          "node": {
            "template": {
              "_type": "Component",
              "tweaks": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tweaks",
                "value": "",
                "display_name": "Tweaks (Optional)",
                "advanced": true,
                "input_types": [
                  "Data",
                  "dict"
                ],
                "dynamic": false,
                "info": "Pass tweaks as a dictionary (e.g., {'LLM_MODEL': {'temperature': 0.5}})",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API Key for authenticating with the target Langflow instance.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_api_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_api_url",
                "value": "https://maia-langflow120-app-v1.whiteisland-eed45fbb.germanywestcentral.azurecontainerapps.io",
                "display_name": "Base API URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The default base URL of the Langflow instance hosting the target flow.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\r\nimport json\r\nimport warnings\r\nfrom typing import Optional, Dict, Any, Tuple\r\nfrom loguru import logger\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, MultilineInput, Output, HandleInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema import Data\r\n\r\ndef _log_error(message: str, response: Optional[requests.Response] = None):\r\n    \"\"\"Helper to format error messages.\"\"\"\r\n    error_message = f\"❌ Error: {message}\"\r\n    details: Dict[str, Any] = {}\r\n    if response is not None:\r\n        details[\"status_code\"] = response.status_code\r\n        try:\r\n            error_details = response.json()\r\n            details[\"response_body\"] = error_details\r\n        except json.JSONDecodeError:\r\n            details[\"response_body\"] = response.text\r\n    return error_message, details\r\n\r\ndef extract_result_text_from_response(response: dict) -> Optional[str]:\r\n    \"\"\"\r\n    Extracts the primary text output from the Langflow response.\r\n    \"\"\"\r\n    try:\r\n        # Check if 'outputs' is in the response\r\n        outputs = response.get('outputs', [])\r\n        if outputs:\r\n            first_output = outputs[0]\r\n            # Navigate to 'outputs' within the first output\r\n            inner_outputs = first_output.get('outputs', [])\r\n            if inner_outputs:\r\n                first_inner_output = inner_outputs[0]\r\n                # Navigate to 'results' within the first inner output\r\n                results = first_inner_output.get('results', {})\r\n                # Navigate to 'message' within 'results'\r\n                message = results.get('message', {})\r\n                # Navigate to 'data' within 'message'\r\n                data = message.get('data', {})\r\n                # Extract the text using 'text_key'\r\n                text_key = message.get('text_key', 'text')\r\n                return data.get(text_key)\r\n        # Fallback: Check if 'result' is in the response\r\n        result = response.get('result', {})\r\n        if isinstance(result, dict):\r\n            message = result.get('message', {})\r\n            if isinstance(message, dict):\r\n                data = message.get('data', {})\r\n                text_key = message.get('text_key', 'text')\r\n                return data.get(text_key)\r\n            elif isinstance(message, str):\r\n                return message\r\n        elif isinstance(result, str):\r\n            return result\r\n        # If no text found, return None\r\n        return None\r\n    except Exception as e:\r\n        warnings.warn(f\"Error parsing response for text: {e}\")\r\n        return None\r\n\r\n\r\nclass LangflowRunnerComponent(Component):\r\n    display_name = \"Langflow Runner\"\r\n    description: str = (\r\n        \"This component should be called if user wants to reset the password\"\r\n    )\r\n    documentation: str = \"https://docs.langflow.org/components/custom\"\r\n    icon = \"Langflow\"\r\n    name = \"LangflowRunner\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"base_api_url\",\r\n            display_name=\"Base API URL\",\r\n            info=\"The default base URL of the Langflow instance hosting the target flow.\",\r\n            required=True,\r\n            value=\"https://your-langflow.instance\"\r\n        ),\r\n        MultilineInput(\r\n            name=\"my_serve_link\",\r\n            display_name=\"My Serve Link\",\r\n            info=\"Optional custom server URL to override the base API URL. Must include http:// or https:// to be used.\",\r\n            required=True,\r\n            # advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"flow_id_or_endpoint\",\r\n            display_name=\"Flow ID or Endpoint Name\",\r\n            info=\"The ID or custom endpoint name of the Langflow flow to run.\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"API Key for authenticating with the target Langflow instance.\",\r\n            required=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"input_value\",\r\n            display_name=\"User Query / Input\",\r\n            info=\"The primary input message/query to send to the target flow.\",\r\n            required=False,\r\n            tool_mode=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"output_type\",\r\n            display_name=\"Output Type\",\r\n            info=\"Expected output type for the API call.\",\r\n            value=\"chat\",\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"input_type\",\r\n            display_name=\"Input Type\",\r\n            info=\"Input type for the API call.\",\r\n            value=\"chat\",\r\n            advanced=True\r\n        ),\r\n        HandleInput(\r\n            name=\"tweaks\",\r\n            display_name=\"Tweaks (Optional)\",\r\n            input_types=[\"Data\", \"dict\"],\r\n            info=\"Pass tweaks as a dictionary (e.g., {'LLM_MODEL': {'temperature': 0.5}})\",\r\n            is_list=False,\r\n            required=False,\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"user_id\",\r\n            display_name=\"User ID\",\r\n            info=\"Unique identifier for the user invoking the component.\",\r\n            required=False,\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"session_id\",\r\n            display_name=\"Session ID\",\r\n            info=\"Optional fallback session ID if the parent graph has none.\",\r\n            required=False,\r\n            # advanced=True\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted Text\", name=\"text_output\", method=\"get_text_output\"),\r\n    ]\r\n\r\n    def _call_target_flow(self) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:\r\n        # Resolve API key\r\n        api_key_value = self.api_key if isinstance(self.api_key, str) else self.api_key.get_secret_value()\r\n\r\n        # # Determine server URL: use custom if valid URL, else fallback\r\n        # custom = getattr(self, 'my_serve_link', None) or ''\r\n        # if custom.startswith('http://') or custom.startswith('https://'):\r\n        #     server_url = custom.rstrip('/')\r\n        # else:\r\n        #     server_url = self.base_api_url.rstrip('/')\r\n        \r\n        custom = getattr(self, 'my_serve_link', None) or ''\r\n        if custom.startswith('http://') or custom.startswith('https://'):\r\n            custom = custom.rstrip('/')\r\n        \r\n        base_url = self.base_api_url.rstrip('/')\r\n\r\n\r\n        api_url = f\"{base_url}/api/v1/run/{self.flow_id_or_endpoint}\"\r\n        headers = {'Content-Type': 'application/json', 'x-api-key': api_key_value}\r\n\r\n        payload: Dict[str, Any] = {\r\n            \"input_value\": self.input_value,\r\n            \"output_type\": self.output_type,\r\n            \"input_type\": self.input_type,\r\n            \"stream\": False,\r\n        }\r\n\r\n        # Session management: parent graph session_id preferred\r\n        parent_sid = getattr(self, 'graph', None) and getattr(self.graph, 'session_id', None)\r\n        final_session_id = parent_sid or getattr(self, 'session_id', None)\r\n        if final_session_id:\r\n            payload[\"session_id\"] = final_session_id\r\n\r\n        # Include user_id if provided\r\n        if getattr(self, 'user_id', None):\r\n            payload[\"user_id\"] = self.user_id\r\n\r\n        # Handle tweaks input\r\n        final_tweaks: Optional[Dict[str, Any]] = None\r\n        if getattr(self, 'tweaks', None):\r\n            if isinstance(self.tweaks, Data) and isinstance(self.tweaks.data, dict):\r\n                final_tweaks = self.tweaks.data\r\n            elif isinstance(self.tweaks, dict):\r\n                final_tweaks = self.tweaks\r\n            else:\r\n                self.status = f\"Error: Invalid tweaks type {type(self.tweaks)}.\"\r\n                return None, self.status\r\n        if final_tweaks:\r\n            payload[\"tweaks\"] = final_tweaks\r\n\r\n        self.status = f\"Calling endpoint: {api_url}\"\r\n        try:\r\n            response = requests.post(api_url, json=payload, headers=headers, timeout=120)\r\n            response.raise_for_status()\r\n            data = response.json()\r\n            self.status = \"API call successful.\"\r\n            return data, None\r\n        except requests.exceptions.HTTPError as e:\r\n            err_msg, details = _log_error(\r\n                f\"API call failed for flow '{self.flow_id_or_endpoint}'\", e.response\r\n            )\r\n            self.status = f\"{err_msg} - Status: {details.get('status_code', 'N/A')}\"\r\n            return None, f\"{err_msg}\\nStatus Code: {details.get('status_code')}\\nResponse: {json.dumps(details.get('response_body', ''))}\"\r\n        except Exception as e:\r\n            logger.exception(\"Unexpected error during API call\")\r\n            msg, _ = _log_error(str(e), getattr(e, 'response', None))\r\n            self.status = msg\r\n            return None, msg\r\n\r\n    def get_raw_output(self) -> Data:\r\n        res, err = self._call_target_flow()\r\n        if err:\r\n            return Data(data={\"error\": err, \"status\": self.status})\r\n        return Data(data=res or {})\r\n\r\n    def get_text_output(self) -> Message:\r\n        res, err = self._call_target_flow()\r\n        if err:\r\n            return Message(text=f\"Error during API call: {err}\")\r\n        text = extract_result_text_from_response(res or {})\r\n        if text is not None:\r\n            self.status = \"Text extracted successfully.\"\r\n            return Message(text=text)\r\n        self.status = \"API call succeeded but text extraction failed.\"\r\n        return Message(text=json.dumps(res, indent=2)[:1000])\r\n\r\n    def build(self, *args, **kwargs) -> Any:\r\n        self.status = \"\"\r\n        missing = [nm for nm, val in [\r\n            ('base_api_url', self.base_api_url),\r\n            ('flow_id_or_endpoint', self.flow_id_or_endpoint),\r\n            ('api_key', self.api_key),\r\n            ('input_value', self.input_value)\r\n        ] if not val]\r\n        if missing:\r\n            self.status = f\"Missing required inputs: {', '.join(missing)}\"\r\n            return Message(text=self.status)\r\n        return self.get_text_output()\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "flow_id_or_endpoint": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "flow_id_or_endpoint",
                "value": "c28b6551-2306-41e8-9141-cae81a5f6c2b",
                "display_name": "Flow ID or Endpoint Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The ID or custom endpoint name of the Langflow flow to run.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "input_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_type",
                "value": "chat",
                "display_name": "Input Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Input type for the API call.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "User Query / Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary input message/query to send to the target flow.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "my_serve_link": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "my_serve_link",
                "value": "https://myserveprod.service-now.com/myserve?id=sc_cat_item&sys_id=0a0a2161ff29c190ac0aecaf435b5ed8",
                "display_name": "My Serve Link",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Optional custom server URL to override the base API URL. Must include http:// or https:// to be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "chat",
                "display_name": "Output Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Expected output type for the API call.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": {
                  "data": {
                    "category": "message",
                    "content_blocks": [],
                    "edit": false,
                    "error": false,
                    "files": [],
                    "flow_id": null,
                    "properties": {
                      "allow_markdown": false,
                      "edited": false,
                      "source": {
                        "display_name": null,
                        "id": null,
                        "source": null
                      },
                      "state": "complete",
                      "targets": []
                    },
                    "sender": null,
                    "sender_name": null,
                    "session_id": "",
                    "text": "",
                    "timestamp": "2025-04-01 18:28:58 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                },
                "display_name": "Session ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Optional fallback session ID if the parent graph has none.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "user_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_id",
                "value": "",
                "display_name": "User ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Unique identifier for the user invoking the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "This component should be called if user wants to reset the password",
            "icon": "Langflow",
            "base_classes": [
              "Message"
            ],
            "display_name": "Langflow Runner",
            "documentation": "https://docs.langflow.org/components/custom",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Extracted Text",
                "method": "get_text_output",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "base_api_url",
              "my_serve_link",
              "flow_id_or_endpoint",
              "api_key",
              "input_value",
              "output_type",
              "input_type",
              "tweaks",
              "user_id",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "LangflowRunner"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 655
        },
        "dragging": false
      },
      {
        "id": "LangflowRunner-MkY4t",
        "type": "genericNode",
        "position": {
          "x": 993.3961415381088,
          "y": 1664.7354667398927
        },
        "data": {
          "id": "LangflowRunner-MkY4t",
          "node": {
            "template": {
              "_type": "Component",
              "tweaks": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tweaks",
                "value": "",
                "display_name": "Tweaks (Optional)",
                "advanced": true,
                "input_types": [
                  "Data",
                  "dict"
                ],
                "dynamic": false,
                "info": "Pass tweaks as a dictionary (e.g., {'LLM_MODEL': {'temperature': 0.5}})",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API Key for authenticating with the target Langflow instance.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_api_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_api_url",
                "value": "https://maia-langflow120-app-v1.whiteisland-eed45fbb.germanywestcentral.azurecontainerapps.io",
                "display_name": "Base API URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The default base URL of the Langflow instance hosting the target flow.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\r\nimport json\r\nimport warnings\r\nfrom typing import Optional, Dict, Any, Tuple\r\nfrom loguru import logger\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, MultilineInput, Output, HandleInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema import Data\r\n\r\ndef _log_error(message: str, response: Optional[requests.Response] = None):\r\n    \"\"\"Helper to format error messages.\"\"\"\r\n    error_message = f\"❌ Error: {message}\"\r\n    details: Dict[str, Any] = {}\r\n    if response is not None:\r\n        details[\"status_code\"] = response.status_code\r\n        try:\r\n            error_details = response.json()\r\n            details[\"response_body\"] = error_details\r\n        except json.JSONDecodeError:\r\n            details[\"response_body\"] = response.text\r\n    return error_message, details\r\n\r\ndef extract_result_text_from_response(response: dict) -> Optional[str]:\r\n    \"\"\"\r\n    Extracts the primary text output from the Langflow response.\r\n    \"\"\"\r\n    try:\r\n        # Check if 'outputs' is in the response\r\n        outputs = response.get('outputs', [])\r\n        if outputs:\r\n            first_output = outputs[0]\r\n            # Navigate to 'outputs' within the first output\r\n            inner_outputs = first_output.get('outputs', [])\r\n            if inner_outputs:\r\n                first_inner_output = inner_outputs[0]\r\n                # Navigate to 'results' within the first inner output\r\n                results = first_inner_output.get('results', {})\r\n                # Navigate to 'message' within 'results'\r\n                message = results.get('message', {})\r\n                # Navigate to 'data' within 'message'\r\n                data = message.get('data', {})\r\n                # Extract the text using 'text_key'\r\n                text_key = message.get('text_key', 'text')\r\n                return data.get(text_key)\r\n        # Fallback: Check if 'result' is in the response\r\n        result = response.get('result', {})\r\n        if isinstance(result, dict):\r\n            message = result.get('message', {})\r\n            if isinstance(message, dict):\r\n                data = message.get('data', {})\r\n                text_key = message.get('text_key', 'text')\r\n                return data.get(text_key)\r\n            elif isinstance(message, str):\r\n                return message\r\n        elif isinstance(result, str):\r\n            return result\r\n        # If no text found, return None\r\n        return None\r\n    except Exception as e:\r\n        warnings.warn(f\"Error parsing response for text: {e}\")\r\n        return None\r\n\r\n\r\nclass LangflowRunnerComponent(Component):\r\n    display_name = \"Langflow Runner\"\r\n    description: str = (\r\n        \"This component should be called if user wants to account reactivation.\"\r\n    )\r\n    documentation: str = \"https://docs.langflow.org/components/custom\"\r\n    icon = \"Langflow\"\r\n    name = \"LangflowRunner\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"base_api_url\",\r\n            display_name=\"Base API URL\",\r\n            info=\"The default base URL of the Langflow instance hosting the target flow.\",\r\n            required=True,\r\n            value=\"https://your-langflow.instance\"\r\n        ),\r\n        MultilineInput(\r\n            name=\"my_serve_link\",\r\n            display_name=\"My Serve Link\",\r\n            info=\"Optional custom server URL to override the base API URL. Must include http:// or https:// to be used.\",\r\n            required=True,\r\n            # advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"flow_id_or_endpoint\",\r\n            display_name=\"Flow ID or Endpoint Name\",\r\n            info=\"The ID or custom endpoint name of the Langflow flow to run.\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"API Key for authenticating with the target Langflow instance.\",\r\n            required=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"input_value\",\r\n            display_name=\"User Query / Input\",\r\n            info=\"The primary input message/query to send to the target flow.\",\r\n            required=False,\r\n            tool_mode=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"output_type\",\r\n            display_name=\"Output Type\",\r\n            info=\"Expected output type for the API call.\",\r\n            value=\"chat\",\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"input_type\",\r\n            display_name=\"Input Type\",\r\n            info=\"Input type for the API call.\",\r\n            value=\"chat\",\r\n            advanced=True\r\n        ),\r\n        HandleInput(\r\n            name=\"tweaks\",\r\n            display_name=\"Tweaks (Optional)\",\r\n            input_types=[\"Data\", \"dict\"],\r\n            info=\"Pass tweaks as a dictionary (e.g., {'LLM_MODEL': {'temperature': 0.5}})\",\r\n            is_list=False,\r\n            required=False,\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"user_id\",\r\n            display_name=\"User ID\",\r\n            info=\"Unique identifier for the user invoking the component.\",\r\n            required=False,\r\n            advanced=True\r\n        ),\r\n        MultilineInput(\r\n            name=\"session_id\",\r\n            display_name=\"Session ID\",\r\n            info=\"Optional fallback session ID if the parent graph has none.\",\r\n            required=False,\r\n            # advanced=True\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted Text\", name=\"text_output\", method=\"get_text_output\"),\r\n    ]\r\n\r\n    def _call_target_flow(self) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:\r\n        # Resolve API key\r\n        api_key_value = self.api_key if isinstance(self.api_key, str) else self.api_key.get_secret_value()\r\n\r\n        # # Determine server URL: use custom if valid URL, else fallback\r\n        # custom = getattr(self, 'my_serve_link', None) or ''\r\n        # if custom.startswith('http://') or custom.startswith('https://'):\r\n        #     server_url = custom.rstrip('/')\r\n        # else:\r\n        #     server_url = self.base_api_url.rstrip('/')\r\n        \r\n        custom = getattr(self, 'my_serve_link', None) or ''\r\n        if custom.startswith('http://') or custom.startswith('https://'):\r\n            custom = custom.rstrip('/')\r\n        \r\n        base_url = self.base_api_url.rstrip('/')\r\n\r\n\r\n        api_url = f\"{base_url}/api/v1/run/{self.flow_id_or_endpoint}\"\r\n        headers = {'Content-Type': 'application/json', 'x-api-key': api_key_value}\r\n\r\n        payload: Dict[str, Any] = {\r\n            \"input_value\": self.input_value,\r\n            \"output_type\": self.output_type,\r\n            \"input_type\": self.input_type,\r\n            \"stream\": False,\r\n        }\r\n\r\n        # Session management: parent graph session_id preferred\r\n        parent_sid = getattr(self, 'graph', None) and getattr(self.graph, 'session_id', None)\r\n        final_session_id = parent_sid or getattr(self, 'session_id', None)\r\n        if final_session_id:\r\n            payload[\"session_id\"] = final_session_id\r\n\r\n        # Include user_id if provided\r\n        if getattr(self, 'user_id', None):\r\n            payload[\"user_id\"] = self.user_id\r\n\r\n        # Handle tweaks input\r\n        final_tweaks: Optional[Dict[str, Any]] = None\r\n        if getattr(self, 'tweaks', None):\r\n            if isinstance(self.tweaks, Data) and isinstance(self.tweaks.data, dict):\r\n                final_tweaks = self.tweaks.data\r\n            elif isinstance(self.tweaks, dict):\r\n                final_tweaks = self.tweaks\r\n            else:\r\n                self.status = f\"Error: Invalid tweaks type {type(self.tweaks)}.\"\r\n                return None, self.status\r\n        if final_tweaks:\r\n            payload[\"tweaks\"] = final_tweaks\r\n\r\n        self.status = f\"Calling endpoint: {api_url}\"\r\n        try:\r\n            response = requests.post(api_url, json=payload, headers=headers, timeout=120)\r\n            response.raise_for_status()\r\n            data = response.json()\r\n            self.status = \"API call successful.\"\r\n            return data, None\r\n        except requests.exceptions.HTTPError as e:\r\n            err_msg, details = _log_error(\r\n                f\"API call failed for flow '{self.flow_id_or_endpoint}'\", e.response\r\n            )\r\n            self.status = f\"{err_msg} - Status: {details.get('status_code', 'N/A')}\"\r\n            return None, f\"{err_msg}\\nStatus Code: {details.get('status_code')}\\nResponse: {json.dumps(details.get('response_body', ''))}\"\r\n        except Exception as e:\r\n            logger.exception(\"Unexpected error during API call\")\r\n            msg, _ = _log_error(str(e), getattr(e, 'response', None))\r\n            self.status = msg\r\n            return None, msg\r\n\r\n    def get_raw_output(self) -> Data:\r\n        res, err = self._call_target_flow()\r\n        if err:\r\n            return Data(data={\"error\": err, \"status\": self.status})\r\n        return Data(data=res or {})\r\n\r\n    def get_text_output(self) -> Message:\r\n        res, err = self._call_target_flow()\r\n        if err:\r\n            return Message(text=f\"Error during API call: {err}\")\r\n        text = extract_result_text_from_response(res or {})\r\n        if text is not None:\r\n            self.status = \"Text extracted successfully.\"\r\n            return Message(text=text)\r\n        self.status = \"API call succeeded but text extraction failed.\"\r\n        return Message(text=json.dumps(res, indent=2)[:1000])\r\n\r\n    def build(self, *args, **kwargs) -> Any:\r\n        self.status = \"\"\r\n        missing = [nm for nm, val in [\r\n            ('base_api_url', self.base_api_url),\r\n            ('flow_id_or_endpoint', self.flow_id_or_endpoint),\r\n            ('api_key', self.api_key),\r\n            ('input_value', self.input_value)\r\n        ] if not val]\r\n        if missing:\r\n            self.status = f\"Missing required inputs: {', '.join(missing)}\"\r\n            return Message(text=self.status)\r\n        return self.get_text_output()\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "flow_id_or_endpoint": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "flow_id_or_endpoint",
                "value": "f7a52fba-92d3-45db-b78e-f21a0c85f669",
                "display_name": "Flow ID or Endpoint Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The ID or custom endpoint name of the Langflow flow to run.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "input_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_type",
                "value": "chat",
                "display_name": "Input Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Input type for the API call.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "User Query / Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary input message/query to send to the target flow.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "my_serve_link": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "my_serve_link",
                "value": "https://myserveprod.service-now.com/myserve?id=sc_cat_item&sys_id=0a0a2161ff29c190ac0aecaf435b5ed8",
                "display_name": "My Serve Link",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Optional custom server URL to override the base API URL. Must include http:// or https:// to be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "chat",
                "display_name": "Output Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Expected output type for the API call.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": {
                  "data": {
                    "category": "message",
                    "content_blocks": [],
                    "edit": false,
                    "error": false,
                    "files": [],
                    "flow_id": null,
                    "properties": {
                      "allow_markdown": false,
                      "edited": false,
                      "source": {
                        "display_name": null,
                        "id": null,
                        "source": null
                      },
                      "state": "complete",
                      "targets": []
                    },
                    "sender": null,
                    "sender_name": null,
                    "session_id": "",
                    "text": "",
                    "timestamp": "2025-04-01 18:28:58 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                },
                "display_name": "Session ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Optional fallback session ID if the parent graph has none.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "user_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_id",
                "value": "",
                "display_name": "User ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Unique identifier for the user invoking the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "This component should be called if user wants to account reactivation.",
            "icon": "Langflow",
            "base_classes": [
              "Message"
            ],
            "display_name": "Langflow Runner",
            "documentation": "https://docs.langflow.org/components/custom",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Extracted Text",
                "method": "get_text_output",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "base_api_url",
              "my_serve_link",
              "flow_id_or_endpoint",
              "api_key",
              "input_value",
              "output_type",
              "input_type",
              "tweaks",
              "user_id",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "LangflowRunner"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 655
        },
        "dragging": false
      },
      {
        "id": "ChatInput-dBpMC",
        "type": "genericNode",
        "position": {
          "x": -674.670602849711,
          "y": 807.4378186302616
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": false,
          "type": "ChatInput",
          "id": "ChatInput-dBpMC"
        },
        "selected": false,
        "measured": {
          "width": 192,
          "height": 65
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-6QNmg",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-HRSWn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-6QNmg{œdataTypeœ:œPromptœ,œidœ:œPrompt-6QNmgœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-HRSWn{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-HRSWnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-6QNmg",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-6QNmgœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-HRSWn",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-HRSWnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-RtDMM",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConditionalRouter-yYK9X",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-RtDMM{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-RtDMMœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConditionalRouter-yYK9X{œfieldNameœ:œllmœ,œidœ:œConditionalRouter-yYK9Xœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-RtDMM",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-RtDMMœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ConditionalRouter-yYK9X",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConditionalRouter-yYK9Xœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-yYK9X",
            "name": "chit_chat",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-HRSWn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-yYK9X{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œchit_chatœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-HRSWn{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-HRSWnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-yYK9X",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œchit_chatœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-HRSWn",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-HRSWnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "OpenAIModel-HRSWn",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HRSWnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Vgcoe",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Vgcoeœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Vgcoe",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-HRSWn",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__OpenAIModel-HRSWn{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HRSWnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Vgcoe{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Vgcoeœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatOutput-Vgcoe",
        "sourceHandle": "{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-Vgcoeœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-yCbbe",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-yCbbeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-yCbbe",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatOutput",
            "id": "ChatOutput-Vgcoe",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatOutput-Vgcoe{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-Vgcoeœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-TextOutput-yCbbe{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-yCbbeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-dBpMC",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-dBpMCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-yYK9X",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-yYK9Xœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-yYK9X",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-dBpMC",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatInput-dBpMC{œdataTypeœ:œChatInputœ,œidœ:œChatInput-dBpMCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-yYK9X{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-yYK9Xœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "LangflowRunner-cCNgz",
        "sourceHandle": "{œdataTypeœ:œLangflowRunnerœ,œidœ:œLangflowRunner-cCNgzœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-i4iQL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-i4iQLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-i4iQL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "LangflowRunner",
            "id": "LangflowRunner-cCNgz",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__LangflowRunner-cCNgz{œdataTypeœ:œLangflowRunnerœ,œidœ:œLangflowRunner-cCNgzœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-i4iQL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-i4iQLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "LangflowRunner-MkY4t",
        "sourceHandle": "{œdataTypeœ:œLangflowRunnerœ,œidœ:œLangflowRunner-MkY4tœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-uA1pU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-uA1pUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-uA1pU",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "LangflowRunner",
            "id": "LangflowRunner-MkY4t",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__LangflowRunner-MkY4t{œdataTypeœ:œLangflowRunnerœ,œidœ:œLangflowRunner-MkY4tœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-uA1pU{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-uA1pUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "CustomComponent-HHgHz",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-HHgHzœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LangflowRunner-cCNgz",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œLangflowRunner-cCNgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "LangflowRunner-cCNgz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-HHgHz",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__CustomComponent-HHgHz{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-HHgHzœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-LangflowRunner-cCNgz{œfieldNameœ:œsession_idœ,œidœ:œLangflowRunner-cCNgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "CustomComponent-HHgHz",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-HHgHzœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LangflowRunner-MkY4t",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œLangflowRunner-MkY4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "LangflowRunner-MkY4t",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-HHgHz",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__CustomComponent-HHgHz{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-HHgHzœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-LangflowRunner-MkY4t{œfieldNameœ:œsession_idœ,œidœ:œLangflowRunner-MkY4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ConditionalRouter-yYK9X",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œreactivate_accountœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LangflowRunner-MkY4t",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLangflowRunner-MkY4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LangflowRunner-MkY4t",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-yYK9X",
            "name": "reactivate_account",
            "output_types": [
              "Message"
            ]
          }
        },
        "className": "",
        "selected": false,
        "id": "xy-edge__ConditionalRouter-yYK9X{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œreactivate_accountœ,œoutput_typesœ:[œMessageœ]}-LangflowRunner-MkY4t{œfieldNameœ:œinput_valueœ,œidœ:œLangflowRunner-MkY4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false
      },
      {
        "source": "ConditionalRouter-yYK9X",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œpassword_resetœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LangflowRunner-cCNgz",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLangflowRunner-cCNgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LangflowRunner-cCNgz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-yYK9X",
            "name": "password_reset",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "xy-edge__ConditionalRouter-yYK9X{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-yYK9Xœ,œnameœ:œpassword_resetœ,œoutput_typesœ:[œMessageœ]}-LangflowRunner-cCNgz{œfieldNameœ:œinput_valueœ,œidœ:œLangflowRunner-cCNgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": 455.7970025797365,
      "y": 272.48070526355593,
      "zoom": 0.28639981864653374
    }
  },
  "description": "Unfolding Linguistic Possibilities.",
  "name": "ESD_COMBINED_FLOW_AS_A_TOOL",
  "last_tested_version": "1.2.0",
  "endpoint_name": null,
  "is_component": false
}